I"ä<h2 id="æ‰§è¡Œè¿‡ç¨‹">æ‰§è¡Œè¿‡ç¨‹</h2>
<ul>
  <li>é€»è¾‘è¿‡ç¨‹
    <pre><code class="language-mermaid">  graph LR
  A[URL]--&gt;B[Request]
  B[Request]--&gt;C[Response]
  C[Response]--&gt;D[Item]
  D[Item]--&gt;E[More]
</code></pre>
  </li>
  <li>ä»£ç æ‰§è¡Œè¿‡ç¨‹: æˆ‘ä»£ç ä¸­ç”¨åˆ°çš„åœ°æ–¹
    <pre><code class="language-mermaid">  graph LR
  A[Spider.start_requests]--&gt;B[Middleware.process_request]
  B[Middleware.process_request]--&gt;C[Spider.parse]
  C[Spider.parse]--&gt;D[Pipeline.process_item]
  D[Pipeline.process_item]--&gt;E[MySQL]
</code></pre>
  </li>
</ul>

<h2 id="é—®æçš„ä¸è§£å†³">é—®æçš„ä¸è§£å†³</h2>

<ol>
  <li>start_urlsåªèƒ½é…ç½®ä¸€ä¸ªæ•°ç»„ï¼Œå¦‚æœæˆ‘æƒ³åŠ¨æ€é…ç½®çˆ¬å–çš„æºå¤´æ€ä¹ˆåŠï¼Ÿ</li>
</ol>

<ul>
  <li>é‡å†™ Spider çš„ start_requests å‡½æ•°ï¼Œåœ¨é‡Œé¢è®¾ç½®è¯·æ±‚</li>
</ul>

<ol>
  <li>å¦‚æœæˆ‘é€šè¿‡è¯·æ±‚ç»“æœï¼Œå‘èµ·æ–°çš„è¯·æ±‚æ€ä¹ˆå†™ï¼Ÿ</li>
</ol>

<ul>
  <li>ç›´æ¥åœ¨ç»“æœé‡Œé¢é€šè¿‡ yieldå‘èµ·è¯·æ±‚</li>
</ul>

<ol>
  <li>å¦‚æœæˆ‘é€šè¿‡è¯·æ±‚ç»“æœå‘èµ·æ–°çš„è¯·æ±‚ï¼Œæ€ä¹ˆå¤„ç†æ–°çš„å“åº”ç»“æœï¼Ÿ
    <ul>
      <li>
        <p>åœ¨Spideré‡Œæ–°å¢éœ€è¦çš„å¤„ç†çš„å‡½æ•°ï¼Œé…ç½® response å‚æ•°å³å¯ã€‚</p>

        <ul>
          <li>
            <p><code class="language-plaintext highlighter-rouge">yield scrapy.Request(next_page, callback=self.parse_new)</code></p>
          </li>
          <li>
            <p><code class="language-plaintext highlighter-rouge">def parse_new(self, response, **kwargs)</code></p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>å¦‚ä½•æŠŠå‘èµ·è¯·æ±‚æ—¶å€™çš„å‚æ•°ä¼ é€’åˆ°å“åº”ç»“æœï¼Ÿ
    <ul>
      <li>é€šè¿‡ Request çš„ meta å‚æ•°ï¼Œä¼ è¾“ä¸€ä¸ªå­—å…¸è¿‡å»ã€‚</li>
      <li>é€šè¿‡ response.meta æ‹¿åˆ°ä½ å­˜å…¥çš„å€¼ã€‚</li>
    </ul>
  </li>
  <li>å¦‚ä½•ç»™Spdieré…ç½®ç‰¹ç‚¹çš„ä¸­é—´ä»¶(middleware)ã€ç®¡é“(pipelines)ï¼Ÿ
    <ul>
      <li>custom_settings
        <ul>
          <li>ITEM_PIPELINES</li>
          <li>SPIDER_MIDDLEWARES</li>
          <li>DOWNLOADER_MIDDLEWARES</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>å¯¹äºä¸€äº›å¼‚æ­¥åŠ è½½çš„é¡µé¢æ€ä¹ˆå¤„ç†ï¼Ÿ
    <ul>
      <li>
        <h5 id="æ–¹æ¡ˆä¸€splash">æ–¹æ¡ˆä¸€ï¼šsplash</h5>
        <ul>
          <li>docker å¯åŠ¨ä¸€ä¸ª Splash ä»£ç†æœåŠ¡ï¼š
            <ul>
              <li><code class="language-plaintext highlighter-rouge">docker run -it -p 8050:8050 --rm scrapinghub/splash</code></li>
            </ul>
          </li>
          <li>settings é…ç½®ï¼š
            <ul>
              <li>
                <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  SPLASH_URL = 'http://host:port'
  DUPEFILTER_CLASS = 'scrapy_splash.SplashAwareDupeFilter'	
  HTTPCACHE_STORAGE = 'scrapy_splash.SplashAwareFSCacheStorage'
 		SPIDER_MIDDLEWARES = {
   		'scrapy_splash.SplashDeduplicateArgsMiddleware': 100,
}	
DOWNLOADER_MIDDLEWARES = {  
   		'scrapy_splash.SplashCookiesMiddleware': 723,
   		'scrapy_splash.SplashMiddleware': 725,
   		'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 810
}
</code></pre></div>                </div>
              </li>
            </ul>
          </li>
          <li>python å¯¼å…¥ä¾èµ–
  <code class="language-plaintext highlighter-rouge">pip3 install scrapy-splash</code></li>
          <li>Spider ä¸­å¼•å…¥
  <code class="language-plaintext highlighter-rouge">from scrapy_splash import SplashRequest</code></li>
          <li>è¯·æ±‚æ›¿æ¢
            <ul>
              <li>ä»ï¼š<code class="language-plaintext highlighter-rouge">scrapy.Request(stock_url, self.parse, meta=params, dont_filter=True)</code></li>
              <li>åˆ°ï¼š<code class="language-plaintext highlighter-rouge">SplashRequest(url, self.parse, meta=params, args={'wait': 0.5})</code></li>
            </ul>
          </li>
          <li>parseæ­£å¸¸è§£æç»“æœå³å¯</li>
        </ul>
      </li>
      <li>
        <h5 id="æ–¹æ¡ˆäºŒselenium">æ–¹æ¡ˆäºŒï¼šselenium</h5>
        <ul>
          <li>python å¯¼å…¥ä¾èµ–
            <ul>
              <li><code class="language-plaintext highlighter-rouge">pip3 install selenium</code></li>
            </ul>
          </li>
          <li>é…ç½® custom_settingsï¼š
            <ul>
              <li><code class="language-plaintext highlighter-rouge">
 		'DOWNLOADER_MIDDLEWARES': {
  	'ht_msg.middlewares.SeleniumDownloadMiddleware': 500
  	}
  	</code></li>
            </ul>
          </li>
          <li>åˆ›å»ºä¸­é—´ä»¶
            <ul>
              <li>```
  from selenium.webdriver.chrome.options import Options
  from selenium import webdriver
  from scrapy.http import HtmlResponse</li>
            </ul>

            <p>class SeleniumDownloadMiddleware(object):
  	  def <strong>init</strong>(self):
     	chrome_options = Options()
     	chrome_options.add_argument(â€˜â€“headlessâ€™)
     	chrome_options.add_argument(â€˜â€“disable-gpuâ€™)
     	chrome_options.add_argument(â€œwindow-size=1024,768â€)
     	chrome_options.add_argument(â€œâ€“no-sandboxâ€)
     	self.driver = webdriver.Chrome(chrome_options=chrome_options)</p>
          </li>
        </ul>

  	  def process_request(self, request, spider):
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     	self.driver.get(request.url)
     	time.sleep(12)
     	source = self.driver.page_source
     	url = self.driver.current_url
     	return HtmlResponse(url=url, body=source, request=request, encoding="utf-8")
	```
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ol>

<h3 id="æœªå®Œå¾…ç»­">æœªå®Œå¾…ç»­â€¦..</h3>

<h3 id="å‚è€ƒçš„æ–‡ä»¶">å‚è€ƒçš„æ–‡ä»¶</h3>

<ul>
  <li>scrapy:
    <ul>
      <li>æ–‡æ¡£
        <ul>
          <li>https://doc.scrapy.org/en/latest/topics/request-response.html#response-objects</li>
        </ul>
      </li>
      <li>æ•™ç¨‹
        <ul>
          <li>https://geek-docs.com/scrapy/scrapy-tutorials/scrapy-css-grammar.html</li>
          <li>https://www.jianshu.com/p/df9c0d1e9087</li>
        </ul>
      </li>
      <li>å¤šç§æ–¹æ¡ˆï¼šçˆ¬å–åŠ¨æ€JS
        <ul>
          <li>https://zhuanlan.zhihu.com/p/130867872</li>
        </ul>
      </li>
      <li>splashæ•™ç¨‹
        <ul>
          <li>https://splash.readthedocs.io/en/stable/</li>
        </ul>
      </li>
      <li>é…ç½®å¯å˜çš„start_urls
        <ul>
          <li>https://blog.csdn.net/sirobot/article/details/105360486</li>
        </ul>
      </li>
      <li>splash
        <ul>
          <li>https://github.com/scrapy-plugins/scrapy-splash</li>
        </ul>
      </li>
      <li>xpath/css
        <ul>
          <li>https://zhuanlan.zhihu.com/p/65143300</li>
        </ul>
      </li>
      <li>ä¸åŒspideré…ç½®ä¸åŒçš„pipline:
        <ul>
          <li>https://blog.csdn.net/peiwang245/article/details/100071316</li>
        </ul>
      </li>
      <li>responseä¼ é€’å‚æ•°ï¼š
        <ul>
          <li>https://blog.csdn.net/killeri/article/details/80255500</li>
        </ul>
      </li>
      <li>spiderçš„settingä¼˜å…ˆçº§
        <ul>
          <li>https://blog.csdn.net/he_ranly/article/details/85092065</li>
        </ul>
      </li>
      <li>ä¸­é—´ä»¶çš„åŒºåˆ«
        <ul>
          <li>https://www.jianshu.com/p/3a9a385b9483</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>scrapyéƒ¨ç½²
    <ul>
      <li>APscheduler
        <ul>
          <li>https://apscheduler.readthedocs.io/en/latest/</li>
        </ul>
      </li>
      <li>subprocess
        <ul>
          <li>https://www.runoob.com/w3cnote/python3-subprocess.html</li>
        </ul>
      </li>
      <li>APscheduler+scarpy
        <ul>
          <li>https://apscheduler.readthedocs.io/en/latest/userguide.html</li>
          <li>https://www.cnblogs.com/jdbc2nju/p/9563761.html</li>
          <li>https://www.jianshu.com/p/c37c46de3168</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
:ET